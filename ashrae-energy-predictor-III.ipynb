{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASHRAE - Great Energy Predictor III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Install Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install feather-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_predict, cross_val_score\n",
    "import math\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Convert Pandas Dataframe to Feather\n",
    "\n",
    "We use a framework called feather for more efficient read and write operations in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data...\n",
    "#root = '/kaggle/input/ashrae-energy-prediction'\n",
    "root = './ashrae-energy-prediction'\n",
    "\n",
    "# Read from csv files\n",
    "train_df = pd.read_csv(os.path.join(root, 'train.csv'))\n",
    "weather_train_df = pd.read_csv(os.path.join(root, 'weather_train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(root, 'test.csv'))\n",
    "weather_test_df = pd.read_csv(os.path.join(root, 'weather_test.csv'))\n",
    "building_meta_df = pd.read_csv(os.path.join(root, 'building_metadata.csv'))\n",
    "sample_submission = pd.read_csv(os.path.join(root, 'sample_submission.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data in feather format\n",
    "train_df.to_feather('train.feather')\n",
    "test_df.to_feather('test.feather')\n",
    "weather_train_df.to_feather('weather_train.feather')\n",
    "weather_test_df.to_feather('weather_test.feather')\n",
    "building_meta_df.to_feather('building_metadata.feather')\n",
    "sample_submission.to_feather('sample_submission.feather')\n",
    "\n",
    "# Delete raw data from memory for better performance\n",
    "del train_df\n",
    "del test_df\n",
    "del weather_train_df\n",
    "del weather_test_df\n",
    "del building_meta_df\n",
    "del sample_submission\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_feather('train.feather')\n",
    "weather_train = pd.read_feather('weather_train.feather')\n",
    "building_meta = pd.read_feather('building_metadata.feather')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Remove Outliers\n",
    "\n",
    "Building 1099 has abnormally higher metering readings than the other buildings.\n",
    "\n",
    "Buildings with id <= 104 has meter readings 0 before 05/20/2016, which is anomaly low.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "train = train[train['building_id'] != 1099]\n",
    "train = train.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Scale Square Feet\n",
    "\n",
    "Since square_feet spans several order of magnitude(some are very big and some are very small, we take the log for better comparability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_meta['square_feet'] =  np.log1p(building_meta['square_feet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3 Handle Missing Values \n",
    "\n",
    "For accuracy and least interference with model fitting, we first group the data base on site_id, month, and day. And fill missing with the daily average in a site.\n",
    "\n",
    "For features such as 'air_temperature' and 'dew_temperature', we can fill both directions because they follow a normal distribution. (We can fill backwards)\n",
    "\n",
    "For 'cloud_coverage', 'sea_level_pressure', 'precip_depth_1_hr', however, we only fill forward because next observation is not indicative of prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def weather_pipeline(weather):\n",
    "    \n",
    "    # Count total number of hours in dataset\n",
    "    time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    start = datetime.datetime.strptime(weather['timestamp'].min(),time_format)\n",
    "    end = datetime.datetime.strptime(weather['timestamp'].max(),time_format)\n",
    "    all_hours = int(((end - start).total_seconds()) / 3600 + 1)\n",
    "    \n",
    "    \n",
    "    timestamps = [(end - datetime.timedelta(hours=x)).strftime(time_format) for x in range(all_hours)]\n",
    "    \n",
    "    \n",
    "    # Add missing timestamps for each site\n",
    "    for site_id in range(16):\n",
    "        split_site_hours = np.array(weather[weather['site_id'] == site_id]['timestamp'])\n",
    "        # Get missing hours\n",
    "        missing_hours = pd.DataFrame(np.setdiff1d(timestamps, split_site_hours), columns=['timestamp'])\n",
    "        missing_hours['site_id'] = site_id\n",
    "        weather = pd.concat([weather, missing_hours])\n",
    "        weather = weather.reset_index(drop=True) \n",
    "    \n",
    "\n",
    "        \n",
    "    weather[\"datetime\"] = pd.to_datetime(weather[\"timestamp\"])\n",
    "    weather[\"day\"] = weather[\"datetime\"].dt.day\n",
    "    weather[\"week\"] = weather[\"datetime\"].dt.week\n",
    "    weather[\"month\"] = weather[\"datetime\"].dt.month\n",
    "    \n",
    "    weather = weather.set_index(['site_id','day','month'])\n",
    "    \n",
    "    \n",
    "    normal = ['air_temperature', 'dew_temperature', 'wind_direction', 'wind_speed']\n",
    "    forward = ['cloud_coverage', 'sea_level_pressure', 'precip_depth_1_hr']\n",
    "    \n",
    "    # Fill both directions with mean\n",
    "    for item in normal:\n",
    "        feature_filler = pd.DataFrame(weather.groupby(['site_id','day','month'])[item].mean(), columns=[item])\n",
    "        weather.update(feature_filler, overwrite=False)\n",
    "    \n",
    "    \n",
    "    # Fill forward \n",
    "    for item in forward:\n",
    "        feature_filler = weather.groupby(['site_id','day','month'])[item].mean()\n",
    "        feature_filler = pd.DataFrame(feature_filler.fillna(method='ffill'),columns=[item])\n",
    "        weather.update(feature_filler,overwrite=False)\n",
    "\n",
    "    weather = weather.reset_index()\n",
    "    weather = weather.drop(['datetime','day','week','month'],axis=1)\n",
    "        \n",
    "    return weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train = weather_pipeline(weather_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.4 Memory Reduction and Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = reduce_mem_usage(train,use_float16=True)\n",
    "building_meta = reduce_mem_usage(building_meta,use_float16=True)\n",
    "weather_train = reduce_mem_usage(weather_train,use_float16=True)\n",
    "\n",
    "train = train.merge(building_meta, left_on='building_id',right_on='building_id',how='left')\n",
    "train = train.merge(weather_train, how='left', left_on=['site_id','timestamp'],right_on=['site_id','timestamp'])\n",
    "del weather_train\n",
    "del building_meta\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.5 Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def FE_pipeline(data):\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    data.sort_values(\"timestamp\")\n",
    "    data.reset_index(drop=True)\n",
    "    \n",
    "    # Add more features\n",
    "    data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"],format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    data[\"hour\"] = data[\"timestamp\"].dt.hour\n",
    "    data[\"day_of_week\"] = data[\"timestamp\"].dt.weekday\n",
    "    \n",
    "    \n",
    "    # Remove Unused Columns\n",
    "    feature_to_drop = [\"timestamp\",\n",
    "                       \"sea_level_pressure\", \n",
    "                       \"wind_direction\", \n",
    "                       \"wind_speed\",\n",
    "                       \"year_built\",\n",
    "                       \"floor_count\"]\n",
    "    data = data.drop(feature_to_drop, axis=1)\n",
    "    gc.collect()\n",
    "    \n",
    "    # Encode Categorical Data\n",
    "    labelencoder = LabelEncoder()\n",
    "    data[\"primary_use\"] = labelencoder.fit_transform(data[\"primary_use\"])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = FE_pipeline(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.6 Fix Unit Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix unit error \n",
    "train.loc[(train['site_id']==0) & (train['meter']==0), 'meter_reading'] = train.loc[(train['site_id']==0)&(train['meter']==0), 'meter_reading'] * 0.2931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[(train.site_id==0)&(train.meter==0)].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Scale Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(train[\"meter_reading\"])\n",
    "X = train.drop('meter_reading', axis = 1)\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Stratified Train-Test Split\n",
    "Since we are training by site, we need to split evenly by site_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test with equal percentage of site id\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle = True, stratify=X['site_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Gradient Boosting, Divide & Conquer, and RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I.\tModel Training\n",
    "    - a.\tAlgorithm: Gradient Boosting\n",
    "        - i.\tGradient Boosting is an ensemble machine learning technique that produces a prediction model by building an ensemble/sequence of weak prediction models (decision trees).\n",
    "        - ii.\tUnlike AdaBoost, which uses stumps, Gradient Boosting builds trees in a stage-wise manner. The general idea of the algorithm is as follow\n",
    "            - 1.\tUse the average of target variables as prediction for every instance;\n",
    "            - 2.\tCompute the Pseudo Residual = Observed – Prediction for each instance;\n",
    "            - 3.\tBuild a decision tree using input variables with residuals as leaves at the lowest level; (If there are multiple residuals in one leaf, take the average of them)\n",
    "            - 4.\tMake a new prediction = Average Observed + Learning Rate x Residual for each instance; We use a Learning Rate to scale in order to prevent high variance(overfitting); Learning Rate results in a small step in the right direction. The model will perform better on testing dataset.\n",
    "            - 5.\tCompute the new Pseudo Residual = (Observed – (Average Observed + Sum of (Learning Rate x Previous Residuals))\n",
    "            - 6.\tBuild a new tree based on new residuals.\n",
    "            - 7.\tRepeat until the maximum number of trees have been reached or additional trees fail to improve the fit.\n",
    "            \n",
    "        - iii. Pseudo Code\n",
    "            - Input: Data {(xi, yi)} for i from 1 to n, and a differentiable loss function(in our case, the RMSLE)\n",
    "            - Step 1: Initialize model with a constant value\n",
    "                      \n",
    "                $$F_0(x) = \\operatorname*{argmin}_\\gamma \\sum_{i=1}^{n} L(y_i, \\gamma)$$\n",
    "            <br><br>\n",
    "            - Step 2: For m = 1 to M where m is the index of tree and M is the maximum number of trees\n",
    "                - (A) Compute:\n",
    "$$r_{i,m} = -[\\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}]_{F(x) = F_{m-1}(x)}$$\n",
    "                    \n",
    "                     for i = 1, ... , n\n",
    "                <br><br>\n",
    "                - (B) Fit regression tree to the $r_{i,m}$ values and create terminal regions $R_{j,m}$, for j = 1...$J_m$ where j is the leaf index and $J_m$ is the number of leaves in tree m\n",
    "                <br> <br>     \n",
    "                - (C) For j = 1...$J_m$, compute: \n",
    "                    $$\\gamma_{j, m} = \\operatorname*{argmin}_\\gamma \\sum_{x_i\\in{R_{i,j}}} L(y_i, F_{m-1}(x_i)+\\gamma)$$\n",
    "                <br> <br> \n",
    "                - (D) Update $$F_m(x) = F_{m-1}(x) + \\nu \\sum_{j=1}^{J_m} \\gamma_{j,m} I(x\\in{R_{j,m}})$$ where $\\nu$ is the learning rate\n",
    "                <br><br>\n",
    "            \n",
    "    - b. Framework: LightGBM\n",
    "        - i. LightGBM was developed by Microsoft based on the idea of XGBoost. The difference between XGBoost and Naive Gradient Boosting which we described earlier is that XGBoost uses an objective Function\n",
    "$$Obj(\\theta) = L(\\theta) + \\Omega(\\theta)$$\n",
    "            where $L(\\theta)$ is the loss function we previously described and $\\Omega(\\theta)$ is the regularization.\n",
    "            <br>\n",
    "            <br>\n",
    "            Let's say we have $f_t(x) = w_q(x), w\\in{R^T}$, q: ${\\mathbb{R}}^d$ -> {1, 2, ... , Q} where w is the leaf weight of the tree and q is the structure of the tree, then\n",
    "            $$\\Omega(f_t) = \\frac{1}{2} \\times \\lambda(\\sum_{j=1}^{Q} {w_j}^{2}) + \\alpha(\\sum_{i=1}^{Q} |w_i|) + \\gamma Q$$\n",
    "            \n",
    "            where $\\lambda$ is XGBoost's lambda, $\\sum_{j=1}^{Q} {w_j}^{2}$ is L1 penalty, $\\alpha$ is XGboost's alpha, $\\sum_{i=1}^{Q} |w_i|$ is L2 penalty, $\\gamma$ is XGBoost's gamma, and Q is the number of leaves.\n",
    "            \n",
    "            <br>\n",
    "            So after combining the loss and regularization, the formula becomes\n",
    "$$ Obj(t) = \\sum_{i=1}^{n} (g_i\\times w_{q(x_i)} + \\frac{h_i}{2} \\times w_{q(x_i)}) + \\frac{1}{2} \\times \\lambda(\\sum_{j=1}^{Q} {w_j}^{2}) + \\alpha(\\sum_{i=1}^{Q} |w_i|) + \\gamma Q$$\n",
    "\n",
    "          $$= \\sum_{j=1}^{Q} [(\\sum_{i\\in{I_j}} g_i \\times w_{q(x_i)} + \\frac{(\\sum_{i\\in{I_j}} h_i) + \\lambda}{2} \\times w_{q_(x_i)} ^ 2] + \\gamma Q$$ \n",
    "          \n",
    "          where $I_j = \\{i|q(x_i) = k\\}$ is a set of indices of points assigned to j-th leaf, $g_i$ and $h_i$ are the gradient(first-degree) and hessian(second-degree) of the loss function.\n",
    "          <br>\n",
    "          For simplification, let\n",
    "          $$ G_j = \\sum_{i\\in{I_j}} g_i$$\n",
    "          $$ H_i = \\sum_{i\\in_{I_j}} h_i$$\n",
    "          <br>\n",
    "          Then, the optimal weight for a fixed tree is \n",
    "          $$w_j^* = - \\frac{G_j}{H_i+\\lambda}$$\n",
    "          <br>\n",
    "          LightGBM grows the tree greedily by computing the gain\n",
    "          $$ Gain = \\frac{1}{2} [\\frac{G_L^2}{H_L+\\lambda} + \\frac{G_R^2}{H_R+\\lambda} - \\frac{(G_L+G_R)}{H_L+H_R+\\lambda}] - \\lambda$$\n",
    "          <br>\n",
    "          where $\\frac{G_L^2}{H_L+\\lambda}$ is the left child score, $\\frac{G_R^2}{H_R+\\lambda}$ is the right child score,  $\\frac{(G_L+G_R)}{H_L+H_R+\\lambda}$ is the score if we do not split, and $\\lambda$ is the complexity cost if we add a new split.\n",
    "          <br>\n",
    "          <br>\n",
    "          LightGBM finds the best split point by iterating over sorted attributes and compute the gain.\n",
    "          <br>\n",
    "          <br>\n",
    "      - ii. Some characteristics of LightGBM\n",
    "      <br>\n",
    "          - Tree is grown in Breadth-First fashion instead of Depth-First so that we can sort and traverse the data only once on each level\n",
    "          <br>\n",
    "          - Sorted features can be cached, so that we don't have to sort many times\n",
    "          <br>\n",
    "          - Each continuous feature is bucketed into discrete bins, and we iterate over number of bins instead of number of points\n",
    "    \n",
    "          \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- c. Training Methodology: Divide and Conquer\n",
    "    - We will split the data by site and train a separate model on each site. \n",
    "    - The reasons:\n",
    "        - 1. There are time zone differences of different sites.\n",
    "        - 2. The size of the data is very large and it is difficult to fit a single model that can generalize on multiple locations despite the advantages of gradient boosting.\n",
    "        - 3. Decrease the training time \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "- d. Evaluation Metric: Since we have already logged the output variable, we can just use RMSE as the evaluation metric which will produce RMSLE.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, cross_val_score\n",
    "import math\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Returns the RMSE of prediction values\n",
    "    \"\"\"\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    y_true = y_true.values\n",
    "    terms_to_sum = 0\n",
    "    for i, pred in enumerate(y_pred):\n",
    "        prediction = y_pred[i] if y_pred[i] > 0 else 0 # Replace negative values with 0\n",
    "        terms_to_sum += (prediction - y_true[i]) ** 2.0\n",
    "    return ((terms_to_sum * (1.0/len(y_true))) ** 0.5)\n",
    "\n",
    "scorer = make_scorer(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 First Attempt\n",
    "We will just use default parameters for now and plot the distribution of our prediction to see how the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"building_id\", \"site_id\", \"meter\", \"primary_use\", \"day_of_week\"]\n",
    "\n",
    "for site_id in range(16):\n",
    "    print('Site:', site_id)\n",
    "    reg = lgb.LGBMRegressor(n_threads=16, verbose=0)\n",
    "    reg.fit(X_train[X_train.site_id==site_id], \n",
    "            y_train[X_train.site_id==site_id], \n",
    "            categorical_feature=categorical_features, \n",
    "            eval_metric='rmse', \n",
    "            verbose=False)\n",
    "    \n",
    "    y_pred = reg.predict(X_test[X_test.site_id==site_id])\n",
    "    \n",
    "    # Plot Distribution\n",
    "    sns.distplot(y_pred, label='Prediction')\n",
    "    sns.distplot(y_test[X_test.site_id==site_id], label='Ground Truth')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "- Site 1, 2, 6, 7, 9, 10, 11, 13, 14, 15 all seem to have an abnormal amount of 0 meter_reading in ground truth which we fail to predict. \n",
    "- The model seems a little bit overfit. We are worried that it will not generalize well on the testing dataset which is twice as big as the training dataset.\n",
    "- Therefore, We will tune the parameters next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 LightGBM parameters:\n",
    "    - 1. learning_rate: Multiplication factor on each boosting iteration; (0, 1]\n",
    "    - 2. n_estimators: Number of boosted tree to fit; Large value can decrease overfitting\n",
    "    - 3. num_leaves: Maximum Number of Leaves; Large value can improve accuracy but expose to overfitting. Typical value is 2 ^ max_depth\n",
    "    - 4. max_depth: Maximum depth of boosted tree; Too deep can cause overfitting\n",
    "    - 5. min_data_in_leaf: Very important parameter to prevent overfitting\n",
    "    - 6. bagging_fraction: Randomly select part of rows(instances); Can be used to prevent overfitting\n",
    "    - 7. feature_fraction: Selecting part of the columns(features); Can be used to deal with the curse of dimensionality \n",
    "    - 8. lambda_l1: l1 regularization\n",
    "    - 9. lambda_l2: l2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Hyperopt Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe, fmin\n",
    "lgb_space = {'boosting': hp.choice('booster', ['gbdt', 'dart']),\n",
    "             'num_leaves': hp.choice('num_leaves', [32, 64, 128, 256, 512, 1024, 2048]),  # The number of leavers per tree\n",
    "             'learning_rate': hp.quniform('learning_rate', 0.001, 0.05, 0.001), # The learning rate of boosted tree\n",
    "             'max_depth': hp.quniform('max_depth', 5, 20, 1), # The maximum depths per tree(prevent overfitting)\n",
    "             'feature_fraction': hp.quniform('feature_fraction', 0.5, 1.0, 0.1), # Percentage of features to use for tree\n",
    "             'bagging_fraction': hp.quniform('bagging_fraction', 0.7, 1.0, 0.1), # Percentage of rows for tree\n",
    "             'min_data_in_leaf': hp.quniform('min_data_in_leaf', 20, 100, 10), # Minimum data in leaf(prevent overfitting) \n",
    "             'lambda_l1' : hp.loguniform('lambda_l1', np.log(0.1), np.log(10)), # l1 regularization(prevent overfitting)\n",
    "             'lambda_l2' : hp.loguniform('lambda_l2', np.log(0.1), np.log(10)) # l2 regularization(prevent overfitting)\n",
    "             #'min_gain_to_split':hp.quniform('min_gain_to_split'0.0, 1.0, 0.1) # gamma\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()\n",
    "del train\n",
    "del X_train\n",
    "del X_test\n",
    "del y_train\n",
    "del y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "best_params = {} # Best parameter for each site\n",
    "\n",
    "for i in range(16):\n",
    "    def lgb_objective(params):\n",
    "        params = {'boosting': params['boosting'],\n",
    "                    'num_leaves': int(params['num_leaves']),\n",
    "                  'learning_rate': params['learning_rate'],\n",
    "                  'max_depth': int(params['max_depth']),\n",
    "                  'feature_fraction': params['feature_fraction'],\n",
    "                  'bagging_fraction': params['bagging_fraction'],\n",
    "                  'min_data_in_leaf': int(params['min_data_in_leaf']),\n",
    "                  'lambda_l1' : params['lambda_l1'],\n",
    "                  'lambda_l2' : params['lambda_l2']}\n",
    "\n",
    "        gbm_reg = lgb.LGBMRegressor(n_estimators=1000, \n",
    "                                    #early_stopping_round=50,\n",
    "                                    n_threads=16, # Multithreading to speed up training\n",
    "                                    #verbose=-1,\n",
    "                                    **params) # Pass in the parameter space\n",
    "\n",
    "        best_score = cross_val_score(gbm_reg, \n",
    "                                     X[X.site_id==i], \n",
    "                                     y[X.site_id==i], \n",
    "                                     fit_params={'verbose' : False,\n",
    "                                                'categorical_feature' : categorical_features}, \n",
    "                                     scoring=scorer,\n",
    "                                     cv=3 # 3 fold cross validation(67% training, 33% evaluation)\n",
    "                                     ).mean()\n",
    "\n",
    "        return best_score\n",
    "    \n",
    "    print(\"Tuning parameter for Site\", i)\n",
    "    \n",
    "    best = fmin(fn=lgb_objective,\n",
    "                    space=lgb_space,\n",
    "                    max_evals=10,\n",
    "                    rstate=np.random.RandomState(42),\n",
    "                    algo=tpe.suggest)\n",
    "    \n",
    "    \n",
    "    print(\"Best Parameter for Site\", i, \": \", best)\n",
    "    \n",
    "    # Save best parameters\n",
    "    best_params[i] = best;\n",
    "    \n",
    "    # Write parameters to file\n",
    "    fname = \"best_params_\" + str(i) + \".txt\"\n",
    "    f = open(fname, \"w+\")\n",
    "    f.write(str(best))\n",
    "    f.close()\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_feather('test.feather')\n",
    "weather_test = pd.read_feather('weather_test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = reduce_mem_usage(test)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Merge Building Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_meta = pd.read_feather('building_metadata.feather')\n",
    "building_meta = reduce_mem_usage(building_meta,use_float16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_meta.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(building_meta, left_on='building_id', right_on='building_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del building_meta\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Fill Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_test = weather_pipeline(weather_test)\n",
    "weather_test = reduce_mem_usage(weather_test)\n",
    "weather_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Merge Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(weather_test, how='left',on=['timestamp','site_id'])\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del weather_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = FE_pipeline(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    best_params[i]['n_threads'] = 16\n",
    "    best_params[i]['metric'] = 'rmse'\n",
    "    best_params[i]['objective'] = 'regression'\n",
    "    best_params[i]['boosting'] = 'gbdt'\n",
    "    best_params[i]['max_depth'] = int(best_params[i]['max_depth'])\n",
    "    best_params[i]['num_leaves'] = int(best_params[i]['num_leaves'])\n",
    "    best_params[i]['min_data_in_leaf'] = int(best_params[i]['min_data_in_leaf'])\n",
    "    print(best_params[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the models\n",
    "models = {}\n",
    "for i in range(16):\n",
    "    models[i] = []\n",
    "\n",
    "# Dictionary to store evaluation results for later graphing\n",
    "eval_results = {}\n",
    "for i in range(16):\n",
    "    eval_results[i] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Fit Models by Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# Make predictions based on sites\n",
    "for site_id in tqdm(range(16), desc='site_id'):\n",
    "    print(\"Training models for Site\", site_id)\n",
    "    \n",
    "    # Create a mask filtering site_id \n",
    "    site_mask = (X.site_id == site_id)\n",
    "    \n",
    "    # Partition training data into 3 parts with equal percentage for each meter type\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True) # 3-fold\n",
    "    fold = 0\n",
    "    for train_indices, test_indices in skf.split(X[site_mask], X[site_mask]['meter']):\n",
    "        print(\"Fold:\", fold)\n",
    "        fold += 1\n",
    "        \n",
    "        X_train = X[site_mask].iloc[train_indices]\n",
    "        y_train = y[site_mask].iloc[train_indices]\n",
    "\n",
    "        X_test = X[site_mask].iloc[test_indices]\n",
    "        y_test = y[site_mask].iloc[test_indices]\n",
    "\n",
    "        d_train = lgb.Dataset(X_train, \n",
    "                              label=y_train, \n",
    "                              categorical_feature=categorical_features, \n",
    "                              free_raw_data=False)\n",
    "        \n",
    "        d_test = lgb.Dataset(X_test, \n",
    "                             label=y_test, \n",
    "                             categorical_feature=categorical_features, \n",
    "                             free_raw_data=False)\n",
    "\n",
    "        \n",
    "        model = lgb.train(best_params[site_id], # The optimal parameters for each site \n",
    "                          train_set=d_train, \n",
    "                          num_boost_round=1000, \n",
    "                          valid_sets=[d_test, d_train],\n",
    "                          valid_names = ['validation', 'train'],\n",
    "                          verbose_eval=0, \n",
    "                          evals_result = eval_results[site_id][fold],\n",
    "                          early_stopping_rounds=50)\n",
    "        \n",
    "        models[site_id].append(model)\n",
    "        \n",
    "        del X_train, y_train, X_test, y_test, d_train, d_test\n",
    "        gc.collect()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Plot learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for site_id in range(16):\n",
    "    print('Learning Curve for Site', site_id)\n",
    "    ax = lgb.plot_metric(eval_results[site_id], metric='rmse')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = test.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols.remove('row_id')\n",
    "input_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['meter'] = test['meter'].astype('category')\n",
    "test['meter'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sites = []\n",
    "for site_id in tqdm(range(16), desc=\"site_id\"):\n",
    "    test_site = test[test.site_id==site_id]\n",
    "    row_ids_site = test_site.row_id\n",
    "\n",
    "    test_site = test_site[input_cols]\n",
    "    y_pred = np.zeros(test_site.shape[0])\n",
    "\n",
    "    print(\"Predicting meter reading for Site\", site_id)    \n",
    "    for fold in range(3):\n",
    "        model = models[site_id][fold]\n",
    "        # We take the average of the prediction result of the 3 models\n",
    "        y_pred += model.predict(test_site, \n",
    "                                          num_iteration=model.best_iteration) / 3\n",
    "        gc.collect()\n",
    "        \n",
    "    df_test_site = pd.DataFrame({\"row_id\": row_ids_site, \n",
    "                                 \"meter_reading\": y_pred})\n",
    "    # convert unit\n",
    "    if(site_id==0):\n",
    "        df_test_site[df_test_site.meter_reading==0] *= 3.4118\n",
    "    df_test_sites.append(df_test_site)\n",
    "    \n",
    "    print(\"Prediction for site_id\", site_id, \"completed\\n\")\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "submit = pd.concat(df_test_sites)\n",
    "submit.meter_reading = np.clip(np.expm1(submit.meter_reading), 0, a_max=None)\n",
    "submit.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
